### Homework 9 ###
# Solo Assignment
---------------------------------------------------------------------------------------------------------------
  ### OBJECTIVE 1 ###
  ### Part A ###
  
#lin_regress <- (y_intercept +(slope(x1)) + rand_var) #note for understanding the formular for simple linear regression
  
#Generate random numbers, starting at the 123 point (setting this point allows the group to get the same generated numbers, took me a while to figure this out)
  
set.seed(123)

#Set values for variables
y_int <- -15
slope <- 17
sigma_values <- c(1, 10, 25)

#Set up an empty data frame
lin_regress_df <-data.frame()

for (sigma in sigma_values) {
  #Generate x values without error
  x <- runif(100, 0, 10)
  #creat an equation for normally distributed error (to use then with y)
  rand_error <- rnorm(100, mean = 0, sd = sigma)
  #Generate y values
  y <- (y_int + (slope*x) + rand_error)
  #Combine values in a data frame by creating a df for the generated values and then combine it with the inital empty dataset
  df <- data.frame(x, y, sigma)
  lin_regress_df <-rbind(lin_regress_df, df)
}
View(lin_regress_df)

---------------
### Part B ###
  #create a graph that has three columns, each displaying one of the three sigma values we were interested in looking at
library(ggplot2)

plot_sigma_var <- ggplot(lin_regress_df, aes(x = x, y = y)) +
    geom_point() +
    facet_wrap(~ sigma, ncol = 3) +
    labs(
     title = "Values of X and Y across different Sigma values",
     x = "x",
     y = "y",
     ) +
  theme_minimal()
    
plot_sigma_var

--------------
### Part C ###
#Q) How does the ability to visually detect a relationship between y and x change as observation error increases?
  
#A) As the observation error increases (the sigma value), the ability to detect a relationship between y and x becomes less clear as the points (visually) become more spread out and less linear. The slope per se of the data is no longer as clear.
  
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
### OBJECTIVE 2 ###
  
### Part A ### 

# Objective - Using simulations of coin flips (Bernoulli trials), plot the probability (number of times out of 100) that you determine the coin is significantly unfair (alpha < 0.05) for 1 to 20 coin flips when p = 0.55.
#Note: The way I am thinking of this is simialr to the CLT demo for set up, that made some sense to me

#Number of times to repeat coin flip
N <- 100
p <- 0.55

#set up an empty vector for simulation output
flip_value <- integer(N+1)
prob_flip <- numeric(N+1)
output_sim = data.frame(flip_value, prob_flip)

#create a for loop to test out flipping a coin 20 times and running that simulation 100 times
## r has a binomial function that I am going to use to look at the probability
for (k in 0:N)
{
  probability <- dbinom(x = 9 , size = 20 , prob = p)
  flip_value[k + 1] <- k
  prob_flip[k + 1] <- probability
}

plot(flip_value, prob_flip)
#So i had the graph working and had bars that all stopped at a prob of 0.12, and now I don't know what happened

## Part B ##


N <- 100
p_mult <- c(0.55, 0.6, 0.65)

#set up an empty vector for simulation output
flip_value <- integer(N+1)
prob_flip <- numeric(N+1)
output_sim_mult = data.frame(flip_value, prob_flip)

#create a for loop to test out flipping a coin 20 times and running that simulation 100 times
## r has a binomial function that I am going to use to look at the probability
for (k in 0:N)
{
  probability <- dbinom(x = 9 , size = 20 , prob = p_mult)
  flip_value[k + 1] <- k
  prob_flip[k + 1] <- probability
}

plot(flip_value, prob_flip)
